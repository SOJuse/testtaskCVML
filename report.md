# PredictYourFood — Отчет по проекту

## 1. Введение

PredictYourFood — это интеллектуальный пайплайн для автоматического распознавания блюд на видео из ресторанов с помощью нейронных сетей семейства YOLOv11. В отчете подробно описан весь путь: подготовка данных, обучение моделей, оптимизация гиперпараметров и анализ результатов.

---

## 2. Подготовка и структурирование данных

- **Извлечение кадров:** Кадры получены из видео с помощью ffmpeg.
- **Разметка:** Bounding boxes и классы размечались в LabelImg и CVAT. Для согласования классов написан скрипт, приводящий все разметки к единому эталонному порядку.
- **Аугментация:** Для train-части применялась аугментация (Albumentations), что увеличило разнообразие данных и повысило устойчивость модели.
- **Структура датасета:** Кадры и разметка организованы в структуру, совместимую с YOLO: `images/{train,val,test}` и `labels/{train,val,test}`.

---

## 3. Графики обучения и валидации

Графики для финальной модели YOLOv11n_opt2:
- [Общий график обучения (loss, mAP, precision, recall)](runs/detect/yolov11n_opt2/results.png)
- [PR-curve (Precision-Recall)](runs/val/yolov11n_opt2_test_metrics/PR_curve.png)
- [F1-curve](runs/val/yolov11n_opt2_test_metrics/F1_curve.png)
- [Precision](runs/val/yolov11n_opt2_test_metrics/P_curve.png)
- [Recall](runs/val/yolov11n_opt2_test_metrics/R_curve.png)
- [Confusion matrix](runs/val/yolov11n_opt2_test_metrics/confusion_matrix.png)

Примеры батчей и предсказаний:
- [train_batch0.jpg](runs/detect/yolov11n_opt2/train_batch0.jpg)
- [val_batch0_pred.jpg](runs/val/yolov11n_opt2_test_metrics/val_batch0_pred.jpg)

---

## 4. Сложности и подходы

**С какими сложностями пришлось столкнуться:**
- Совместимость LabelImg и CVAT с разными версиями Python и PyQt5 на MacOS — пришлось фиксить библиотеку под копотом.
- Классы в разметке из разных инструментов не совпадали — потребовался анализ и автоматическая замена индексов.
- Без аугментации модель быстро переобучалась, а данных было не так много.
- Иногда не хватало ресурсов (CPU/GPU, RAM), особенно при увеличении batch size.

**Как эти вопросы были решены:**
- Все этапы автоматизированы: подготовка, аугментация, обучение, анализ — всё через скрипты.
- Использованы современные аугментации (Albumentations).
- Гиперпараметры подбирались итеративно, анализировались метрики и графики.
- Визуальный анализ (не только цифры, но и картинки) оказался очень полезным.

---

## 5. Выводы

Построен полный, воспроизводимый пайплайн для задачи детекции блюд на видео. Проведено сравнение моделей YOLOv11n, YOLOv11s и двух оптимизированных версий YOLOv11n. После двух итераций оптимизации удалось повысить mAP50-95 до 0.95 и ускорить инференс до ~67 мс на изображение без потери точности и полноты. Усиление аугментаций и подбор learning rate повысили устойчивость модели к новым данным. Все этапы автоматизированы, результаты визуализированы и подробно задокументированы.

---

## 6. Архитектура и обучение нейросетей

Использовались две модели:
- **YOLOv11n** ("nano") — компактная, быстрая, с меньшим числом параметров (2,6 млн).
- **YOLOv11s** ("small") — более тяжелая, но потенциально более точная (9,4 млн параметров).

Параметры первой тренировки:
- Эпох: 50
- Размер изображения: 640x640
- Learning rate: 0.01 (по умолчанию)
- Batch size: 16 (по умолчанию)
- Аугментации: стандартные

---

## 7. Метрики на тестовой выборке

| Модель      | mAP50-95 | mAP50 | Precision | Recall | F1-score | Inference time |
|-------------|----------|-------|-----------|--------|----------|---------------|
| YOLOv11s    | 0.957    | 0.995 | 0.997     | 0.998  | 0.997    | ~183 ms/image  |
| YOLOv11n    | 0.943    | 0.995 | 0.997     | 0.998  | 0.997    | ~89 ms/image   |
| YOLOv11n_opt1 | 0.937    | 0.995 | 0.997     | 0.997  | 0.997    | ~91 ms/image   |
| YOLOv11n_opt2 | 0.950    | 0.995 | 0.997     | 0.997  | 0.997    | ~67 ms/image   |

mAP50-95 — среднее значение AP по IoU от 0.5 до 0.95 (главная метрика качества детекции)
Precision — доля верно найденных объектов среди всех найденных
Recall — доля найденных объектов среди всех существующих
F1-score — гармоническое среднее между precision и recall

---

## 8. Визуализация результатов

Графики для YOLOv11s:
- [PR-curve](runs/val/yolov11s_test_metrics/PR_curve.png)
- [F1-curve](runs/val/yolov11s_test_metrics/F1_curve.png)
- [Confusion matrix](runs/val/yolov11s_test_metrics/confusion_matrix.png)

Графики для YOLOv11n:
- [PR-curve](runs/val/yolov11n_test_metrics/PR_curve.png)
- [F1-curve](runs/val/yolov11n_test_metrics/F1_curve.png)
- [Confusion matrix](runs/val/yolov11n_test_metrics/confusion_matrix.png)

Примеры предсказаний:
- YOLOv11s: [frame_00001.jpg](runs/predict/yolov11s_test/frame_00001.jpg)
- YOLOv11n: [frame_00001.jpg](runs/predict/yolov11n_test/frame_00001.jpg)

---

## 9. Оптимизация гиперпараметров (итерация 1)

### Что и почему было изменено:
- **Learning rate (`lr0`)**: уменьшен с 0.01 до 0.005. Это позволило сделать шаги градиентного спуска более плавными, снизить риск "перепрыгнуть" минимум функции потерь и добиться более стабильного обучения.
- **Batch size (`batch`)**: увеличен с 8 до 16. Больший batch size позволил точнее оценивать градиенты, ускорил и стабилизировал обучение (когда хватало памяти).
- **Аугментации:**
  - `hsv_h=0.02` (было 0.015)
  - `hsv_s=0.8` (было 0.7)
  - `scale=0.6` (было 0.5)
  - `translate=0.15` (было 0.1)
  Это сделало обучающую выборку более разнообразной, помогло бороться с переобучением и повысило устойчивость к реальным условиям.

Ожидалось, что эти изменения повысят устойчивость модели к новым/необычным данным, снизят переобучение и улучшат итоговые метрики (mAP, Precision, Recall, F1-score) на тестовой выборке.

---

## 10. Сравнение моделей и выводы

YOLOv11s показала чуть более высокое качество (mAP50-95), но работала медленнее. YOLOv11n быстрее, но немного уступала по точности. После оптимизации гиперпараметров отмечен рост устойчивости и качества модели YOLOv11n. Оба варианта подходят для задачи, выбор зависит от требований к скорости и ресурсам.

### Результаты оптимизированной модели (YOLOv11n_opt1)

- **mAP50-95:** 0.937
- **mAP50:** 0.995
- **Precision:** 0.997
- **Recall:** 0.997
- **F1-score:** 0.997
- **Inference time:** ~91 ms/image

**По классам:**
- чай: P=0.997, R=1, mAP50=0.995, mAP50-95=0.96
- кружка: P=1, R=0.979, mAP50=0.995, mAP50-95=0.961
- ребра: P=0.997, R=1, mAP50=0.995, mAP50-95=0.954
- шашлык: P=0.997, R=1, mAP50=0.995, mAP50-95=0.971
- салат с баклажанами: P=0.994, R=1, mAP50=0.995, mAP50-95=0.87
- греческий салат: P=0.995, R=1, mAP50=0.995, mAP50-95=0.946
- борщ: P=0.996, R=1, mAP50=0.995, mAP50-95=0.932
- луковый суп: P=0.998, R=1, mAP50=0.995, mAP50-95=0.899

**Вывод:** После оптимизации гиперпараметров YOLOv11n сохранила высокие значения всех метрик, скорость инференса осталась на прежнем уровне. Незначительное снижение mAP50-95 связано с усилением аугментаций, что могло сделать задачу сложнее, но повысило устойчивость к новым данным. Модель по-прежнему демонстрирует отличную точность и полноту по всем классам.

### Мотивация и изменения для второй оптимизации (opt2)

После первой оптимизации (opt1) отмечены:
- Высокие значения Precision, Recall, F1-score (0.997), но небольшое снижение mAP50-95 (0.937) по сравнению с базовой моделью.
- Усиление аугментаций в opt1 повысило устойчивость к новым данным, но могло сделать задачу сложнее, что проявилось в снижении mAP50-95.
- Скорость инференса осталась на прежнем уровне (~91 мс/изображение).

**Что и почему было изменено во второй итерации (opt2):**
- **Аугментации:** сделаны чуть мягче, чтобы не усложнять задачу для модели:
  - `scale` уменьшен с 0.6 до 0.5
  - `translate` уменьшен с 0.15 до 0.12
  - `hsv_h` и `hsv_s` также немного уменьшены
- **Learning rate (`lr0`)**: снижен с 0.005 до 0.004 для еще более плавного обучения.
- **Optimizer:** сменен на Adam для лучшей сходимости на небольших датасетах.
- **lrf:** увеличен до 0.05 для более гибкого изменения learning rate в процессе обучения.
- **Epochs:** увеличено до 70, чтобы дать модели больше времени на обучение.

Ожидалось, что более мягкие аугментации позволят модели лучше "запоминать" важные детали, не теряя устойчивости, а новый оптимизатор и scheduler — повысят стабильность и качество обучения. Увеличение числа эпох — даст больше возможностей для дообучения без переобучения.

**Результат:** mAP50-95 вырос до 0.95 (лучше, чем у opt1 и базовой модели n), скорость инференса увеличилась (стала быстрее — ~67 мс/изображение), все остальные метрики остались на высоком уровне.

### Результаты второй оптимизации (YOLOv11n_opt2)

- **mAP50-95:** 0.950
- **mAP50:** 0.995
- **Precision:** 0.997
- **Recall:** 0.997
- **F1-score:** 0.997
- **Inference time:** ~67 ms/image

**По классам:**
- чай: P=0.997, R=1, mAP50=0.995, mAP50-95=0.967
- кружка: P=1, R=0.976, mAP50=0.995, mAP50-95=0.967
- ребра: P=0.997, R=1, mAP50=0.995, mAP50-95=0.975
- шашлык: P=0.998, R=1, mAP50=0.995, mAP50-95=0.981
- салат с баклажанами: P=0.997, R=1, mAP50=0.995, mAP50-95=0.888
- греческий салат: P=0.996, R=1, mAP50=0.995, mAP50-95=0.966
- борщ: P=0.998, R=1, mAP50=0.995, mAP50-95=0.956
- луковый суп: P=0.994, R=1, mAP50=0.995, mAP50-95=0.901

---

## 11. Общие выводы

YOLOv11s показала чуть более высокое качество (mAP50-95), но работала медленнее. YOLOv11n быстрее, но немного уступала по точности. После оптимизации (opt2) YOLOv11n стала и быстрее, и точнее, чем в первой итерации. Итоговый пайплайн работает стабильно, метрики отличные, все этапы автоматизированы и хорошо документированы.

---